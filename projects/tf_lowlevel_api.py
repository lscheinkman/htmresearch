# -*- coding: utf-8 -*-
"""tf_lowlevel_api.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DTMKpZqzKSfpi-p3qh73VvXF9dMkiJpd
"""
from datetime import datetime

import numpy as np
import tensorflow as tf
import tensorflow.keras as keras
import nupic
from nupic.bindings.math import *

BATCH_SIZE = 4
EPOCHS = 1

N = 500
K = 50

BOOST_STRENGTH = 1.0
BOOST_STRENGTH_FACTOR = 0.9
WEIGHT_SPARSITY = 0.4
K_INFERENCE_FACTOR = 2.0

INPUT_SIZE = 28*28
SEED = 42
tf.set_random_seed(SEED)



def Dense(inputs, units, activation=None, name="dense"):
  """
  NN layer using dense tensors: output = activation(dot(x, weights) + bias)
  """
  with tf.variable_scope(name):
    input_size = inputs.shape[-1].value
    w = tf.get_variable(name='weight',
                        shape=(input_size, units),
                        initializer=tf.glorot_uniform_initializer())
    b = tf.get_variable(name='bias',
                        shape=(1, units),
                        initializer=tf.zeros_initializer())
    outputs = tf.matmul(inputs, w) + b
    if activation is not None:
      outputs = activation(outputs)
    return outputs



def Sparse(inputs, units, sparsity=0.5, activation=None, name="sparse"):
  """
  NN layer using sparse tensors: output = activation(dot(x, weights) + bias)
  """
  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):
    input_size = inputs.shape[-1].value
    nonzeros = int(round(units * sparsity))
    dense_shape = [input_size, units]

    # Compute sparse indices
    idx = np.stack(np.indices(dense_shape), axis=-1)
    map(np.random.shuffle, idx)
    idx = idx[:, :nonzeros]
    idx = np.sort(idx, axis=1)
    indices = np.reshape(idx, (-1, 2))

    w = tf.get_variable('weights', [input_size * nonzeros],
                        initializer=tf.random_normal_initializer())
    b = tf.get_variable('bias', [units],
                        initializer=tf.zeros_initializer())
    sp_w = tf.SparseTensor(indices=indices, values=w, dense_shape=dense_shape)

    outputs = tf.sparse.matmul(sp_w, inputs, adjoint_a=True, adjoint_b=True)
    outputs = tf.transpose(outputs) + b

    if activation is not None:
      outputs = activation(outputs)
    return outputs



def DenseNN(inputs, hidden, output, name="DenseNN"):
  """
  Simple NN model using dense tensors: inputs => relu(l1) => l2 => outputs

  Note:
    Return logits not probabilities.
    The output of this model can be trained with the loss function:
      `tf.losses.sparse_softmax_cross_entropy`
    The caller should use `tf.nn.softmax` to get the probabilities from the logits
  """
  with tf.variable_scope(name):
    l1 = Dense(inputs=inputs, units=hidden, activation=tf.nn.relu, name="l1")
    l2 = Dense(inputs=l1, units=output, name="l2")
    return l2



def SparseNN(inputs, hidden, output, name="SparseNN"):
  """
  Simple NN model using sparse tensors:
    inputs => relu(sparse(l1)) => l2 => outputs

  Note:
    Return logits not probabilities.
    The output of this model can be trained with the loss function:
      `tf.losses.sparse_softmax_cross_entropy`
    The caller should use `tf.nn.softmax` to get the probabilities from the logits
  """
  with tf.variable_scope(name):
    l1 = Sparse(inputs=inputs, units=hidden, sparsity=WEIGHT_SPARSITY,
                activation=tf.nn.relu, name="l1")
    l2 = Dense(inputs=l1, units=output, name="l2")
    return l2



def createDataset(image_data, label_data, name="Dataset"):
  with tf.name_scope(name):
    dataset = tf.data.Dataset.from_tensor_slices((image_data, label_data))
    dataset = dataset.shuffle(1000)
    dataset = dataset.batch(BATCH_SIZE)
    iterator = dataset.make_initializable_iterator()
    return iterator



def main1():
  # Load MNIST training and test datasets into numpy arrrays
  (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

  INPUT_SIZE = 28 * 28
  x_train = x_train.reshape(-1, INPUT_SIZE) / 255.0
  x_test = x_test.reshape(-1, INPUT_SIZE) / 255.0

  image_data = tf.placeholder(name="image", shape=[None, INPUT_SIZE], dtype=tf.float32)
  label_data = tf.placeholder(name="label", shape=[None], dtype=tf.int32)
  iterator = createDataset(image_data, label_data, name="MNIST")
  image, label = iterator.get_next()

  # Build
  output = SparseNN(image, N, 10)

  # Train
  with tf.name_scope("Training"):
    loss = tf.losses.sparse_softmax_cross_entropy(labels=label, logits=output)
    optimizer = tf.train.AdamOptimizer().minimize(loss)

  # Test
  with tf.name_scope("Testing"):
    predictions = tf.argmax(tf.nn.softmax(output), axis=-1, output_type=tf.int32)
    correct = tf.equal(predictions, label)
    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))

  log_dir = "logs/lowlevel/SparseNN/{}".format(datetime.now())
  writer = tf.summary.FileWriter(log_dir, tf.get_default_graph())
  run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)

  with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())

    # Training loop
    print("Training")
    start_time = datetime.now()
    sess.run(iterator.initializer, feed_dict={image_data: x_train,
                                              label_data: y_train})
    try:
      total_loss = 0.0
      total_accuracy = 0.0
      n_batches = 0
      run_metadata = tf.RunMetadata()
      while True:
        _, l, acc = sess.run([optimizer, loss, accuracy],
                             run_metadata=run_metadata, options=run_options)
        total_loss += l
        total_accuracy += acc
        n_batches += 1
    except tf.errors.OutOfRangeError:
      pass

    total_time = (datetime.now() - start_time).total_seconds()
    print("=" * 80)
    print('Total time: {0:.2f}s - {1:.2f}µs/image'
          .format(total_time, float(total_time) / len(x_train) / 1e-6))
    print('Average loss : {0}'.format(total_loss / n_batches))
    print('Accuracy : {0}'.format(total_accuracy / n_batches))
    writer.add_run_metadata(run_metadata, "train")

    # Test loop
    print("Testing")
    start_time = datetime.now()
    sess.run(iterator.initializer, feed_dict={image_data: x_test,
                                              label_data: y_test})
    try:
      total_accuracy = 0.0
      n_batches = 0
      run_metadata = tf.RunMetadata()
      while True:
        acc = sess.run(accuracy,
                       run_metadata=run_metadata, options=run_options)
        total_accuracy += acc
        n_batches += 1
    except tf.errors.OutOfRangeError:
      pass

    total_time = (datetime.now() - start_time).total_seconds()
    print("=" * 80)
    print('Total time: {0:.2f}s - {1:.2f}µs/image'
          .format(total_time, float(total_time) / len(x_train) / 1e-6))
    print('Accuracy : {0}'.format(total_accuracy / n_batches))
    writer.add_run_metadata(run_metadata, "test")

  writer.close()



def main2():
  # Load MNIST training and test datasets into numpy arrrays
  (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

  INPUT_SIZE = 28 * 28
  x_train = x_train.reshape(-1, INPUT_SIZE) / 255.0

  image_data = tf.placeholder(name="image", shape=[None, INPUT_SIZE], dtype=tf.float32)
  label_data = tf.placeholder(name="label", shape=[None], dtype=tf.int32)
  iterator = createDataset(image_data, label_data, name="MNIST")
  image, label = iterator.get_next()

  dense = Dense(name="Dense", inputs=image, units=N)
  sparse = Sparse(name="Sparse", inputs=image, sparsity=WEIGHT_SPARSITY, units=N)

  log_dir = "logs/lowlevel/DenseSparse/{}".format(datetime.now())
  writer = tf.summary.FileWriter(log_dir, tf.get_default_graph())
  run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)

  with tf.Session() as sess:
    print("Sparse")
    sess.run(tf.global_variables_initializer())
    sess.run(iterator.initializer, feed_dict={image_data: x_train,
                                              label_data: y_train})
    start_time = datetime.now()
    try:
      run_metadata = tf.RunMetadata()
      while True:
        sess.run(sparse, run_metadata=run_metadata, options=run_options)
    except tf.errors.OutOfRangeError:
      pass

    total_time = (datetime.now() - start_time).total_seconds()
    print("=" * 80)
    print('Total time: {0:.2f}s - {1:.2f}µs/image'
          .format(total_time, float(total_time) / len(x_train) / 1e-6))
    writer.add_run_metadata(run_metadata, "sparse")

    print("Dense")
    sess.run(tf.global_variables_initializer())
    sess.run(iterator.initializer, feed_dict={image_data: x_train,
                                              label_data: y_train})
    start_time = datetime.now()
    try:
      run_metadata = tf.RunMetadata()
      while True:
        sess.run(dense, run_metadata=run_metadata, options=run_options)
    except tf.errors.OutOfRangeError:
      pass

    total_time = (datetime.now() - start_time).total_seconds()
    print("=" * 80)
    print('Total time: {0:.2f}s - {1:.2f}µs/image'
          .format(total_time, float(total_time) / len(x_train) / 1e-6))
    writer.add_run_metadata(run_metadata, "dense")

def main3():
  nonzeros = int(round(N * WEIGHT_SPARSITY))
  dense_shape = [INPUT_SIZE, N]
  input_values = np.float32(np.random.uniform(size=[BATCH_SIZE, INPUT_SIZE]))
  sp_values = np.float32(np.random.uniform(size=INPUT_SIZE * nonzeros))

  # Input as SparseMatrix
  inputs = SM32(input_values)

  # Initialize SparseMatrix
  rows, cols = np.indices(dense_shape)
  rows = rows[:, :nonzeros]
  map(np.random.shuffle, cols)
  cols = cols[:, :nonzeros]
  kernel = SM32(INPUT_SIZE, N)
  kernel.setElements(rows.flat, cols.flat, sp_values)

  start_time = datetime.now()
  res = inputs * kernel
  total_time = (datetime.now() - start_time).total_seconds()
  print "total time: {0:.2f}µs".format(total_time / BATCH_SIZE / 1e-6)


if __name__ == "__main__":
  main2()
